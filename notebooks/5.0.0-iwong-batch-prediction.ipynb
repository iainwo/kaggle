{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "input_filepath = '../models/'\n",
    "pred_filepath = '../data/raw/'\n",
    "output_filepath = '../data/predictions/'\n",
    "\n",
    "# prediction data\n",
    "PRED_CSV = Path.cwd().joinpath(pred_filepath).joinpath('unlabeled.csv')\n",
    "PRED_CSV_OUT = Path.cwd().joinpath(output_filepath).joinpath('preds.csv')\n",
    "\n",
    "# cols\n",
    "BINARY_COLS = Path.cwd().joinpath(input_filepath).joinpath('binary-cols.pickle')\n",
    "CATEGORICAL_COLS = Path.cwd().joinpath(input_filepath).joinpath('categorical-cols.pickle')\n",
    "CONTINUOUS_COLS = Path.cwd().joinpath(input_filepath).joinpath('continuous-cols.pickle')\n",
    "TARGET_COL = Path.cwd().joinpath(input_filepath).joinpath('target-col.pickle')\n",
    "\n",
    "COL_ORDER = Path.cwd().joinpath(input_filepath).joinpath('col-order.pickle')\n",
    "\n",
    "# metadata\n",
    "BINARY_ENCODERS = Path.cwd().joinpath(input_filepath).joinpath('binary-encoders.pickle')\n",
    "CATEGORICAL_ENCODERS = Path.cwd().joinpath(input_filepath).joinpath('categorical-encoders.pickle')\n",
    "TARGET_ENCODERS = Path.cwd().joinpath(input_filepath).joinpath('target-encoders.pickle')\n",
    "CONTINUOUS_SCALERS = Path.cwd().joinpath(input_filepath).joinpath('continuous-scalers.pickle')\n",
    "\n",
    "# model\n",
    "MODEL = Path.cwd().joinpath(input_filepath).joinpath('catboost_model.dump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def read_obj(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x12314e0b8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cols\n",
    "binary_cols = read_obj(BINARY_COLS)\n",
    "categorical_cols = read_obj(CATEGORICAL_COLS)\n",
    "continuous_cols = read_obj(CONTINUOUS_COLS)\n",
    "target_col = read_obj(TARGET_COL)\n",
    "\n",
    "col_order = read_obj(COL_ORDER)\n",
    "\n",
    "# Metadata\n",
    "ohe_encoders = read_obj(BINARY_ENCODERS)\n",
    "label_encoders = read_obj(CATEGORICAL_ENCODERS)\n",
    "scalers = read_obj(TARGET_ENCODERS)\n",
    "target_encoders = read_obj(CONTINUOUS_SCALERS)\n",
    "\n",
    "# Data\n",
    "df = pd.read_csv(PRED_CSV)\n",
    "df = df[binary_cols + categorical_cols + continuous_cols + [target_col]]\n",
    "\n",
    "# Model\n",
    "model = CatBoostClassifier()\n",
    "model.load_model(str(MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39308, 186)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def normalize(df, cols, scalers=None):\n",
    "    if None is scalers:\n",
    "        scalers = dict()\n",
    "        \n",
    "    for col in cols:\n",
    "        if col not in scalers:\n",
    "            scalers[col] = StandardScaler(with_mean=True, with_std=True)\n",
    "            scalers[col].fit(df[col].values.reshape(-1,1))\n",
    "        \n",
    "        scaler = scalers[col]\n",
    "        df[col] = scaler.transform(df[col].values.reshape(-1,1))\n",
    "    return df, scalers\n",
    "\n",
    "def labelencode(df, cols, encoders=None, unknown_value='UNK'):\n",
    "    if None is encoders:\n",
    "        encoders = dict()\n",
    "        \n",
    "    for col in cols:\n",
    "        if col not in encoders:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(df[col].values)\n",
    "            \n",
    "            # add unknown val to cats\n",
    "            cats = le.classes_.tolist()\n",
    "            bisect.insort_left(cats, unknown_value)\n",
    "            \n",
    "            # redefine cats on le\n",
    "            le.classes_ = np.asarray(cats)\n",
    "\n",
    "            encoders[col] = le\n",
    "        \n",
    "        le = encoders[col]\n",
    "        df[col] = df[col].map(lambda x: unknown_value if x not in le.classes_ else x)\n",
    "        df[col] = le.transform(df[col].values)\n",
    "        \n",
    "    return df, encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# cast\n",
    "df[continuous_cols] = df[continuous_cols].astype('float32')\n",
    "df[categorical_cols] = df[categorical_cols].astype('str').astype('category')\n",
    "df[binary_cols] = df[binary_cols].astype('str').astype('category')\n",
    "df[target_col] = df[target_col].astype('str').astype('category')\n",
    "\n",
    "# fill\n",
    "df[continuous_cols] = df[continuous_cols].fillna(0)\n",
    "\n",
    "# normalize, labelencode, ohe\n",
    "df, _ = normalize(df, continuous_cols, scalers)\n",
    "df, _ = labelencode(df, categorical_cols, label_encoders)\n",
    "df, _ = labelencode(df, [target_col], target_encoders)\n",
    "df, _ = labelencode(df, binary_cols, ohe_encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Create Pred Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "if target_col in col_order:\n",
    "    col_order.remove(target_col)\n",
    "X = X[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_preds = model.predict(X)\n",
    "y_proba = model.predict_proba(X)\n",
    "y_proba_death = y_proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y_proba_death, columns=['hospital_death'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Persist Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "arr = scalers['encounter_id'].inverse_transform(X['encounter_id'])\n",
    "X_encounter_id = round(pd.DataFrame(arr, columns=['encounter_id'])) # round for numerical errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pd.concat([X_encounter_id, y], axis=1).to_csv(PRED_CSV_OUT, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wids-datathon-2020",
   "language": "python",
   "name": "valence"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
